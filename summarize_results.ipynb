{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cace3646-122f-4535-b354-06b0cc28c215",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Finalizing the previous step results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa635de-2b0b-4b06-87c7-85b04ff5e07a",
   "metadata": {},
   "source": [
    "# Findings\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a032f75-b6a8-4477-aefa-b28700c4a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import chime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3623808-4705-4c4f-a371-00cabdcf7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext chime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab9d3c-f366-4ce0-9b2b-a5a6ae8b2010",
   "metadata": {},
   "source": [
    "# Inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692ef56-ea1f-4f72-97b7-6bc9072cdbe8",
   "metadata": {},
   "source": [
    "Original corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54db454-327e-47ae-b0b7-33e975010838",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_corpus = 'legal_clauses.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22aa619e-cbaa-4081-9341-6eac3fac70ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(filename_corpus, 'r') as f:\n",
    "    tokens = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e063257-7553-496e-8778-3297e0098fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849299f9-72ec-4015-998c-e8cae7a917e3",
   "metadata": {},
   "source": [
    "Set phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96122ac-e349-4b6c-b750-2e34b616dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('set_phrases.json', 'r') as f:\n",
    "    set_phrases = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b241d-c140-4314-93f3-bcca5bcd4519",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4aa42f-f193-4f96-9a6a-08521f2bbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'phrase': set_phrases})\n",
    "df['tokenized'] = df.phrase.apply(lambda x: tuple(nltk.word_tokenize(x)))\n",
    "df['word_count'] = df.tokenized.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b56633-3c0e-4184-86b1-8c8ac5cbb83c",
   "metadata": {},
   "source": [
    "Remove phrases consisting of stop words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a3d738-63e5-4f28-999c-7a82a06fed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50903a16-b1c1-4dc8-88a8-9131dce3dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_only(row, stopwords):\n",
    "    diff = set(row.tokenized) - stopwords\n",
    "    return len(diff) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a2a5e1-8a29-404f-bdf9-516022d07440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['only_stopwords'] = df.apply(stopwords_only, axis=1, stopwords=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4317f2-dd88-4d3d-8aee-6943d0c0200b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>including attorneys fees</td>\n",
       "      <td>(including, attorneys, fees)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>without the prior written consent</td>\n",
       "      <td>(without, the, prior, written, consent)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act u s c et seq</td>\n",
       "      <td>(act, u, s, c, et, seq)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject to the provisions of</td>\n",
       "      <td>(subject, to, the, provisions, of)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internal revenue code</td>\n",
       "      <td>(internal, revenue, code)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>not reasonably be expected to result in a mate...</td>\n",
       "      <td>(not, reasonably, be, expected, to, result, in...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>represents warrants and covenants</td>\n",
       "      <td>(represents, warrants, and, covenants)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>taken or omitted</td>\n",
       "      <td>(taken, or, omitted)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>consummation of the transactions contemplated</td>\n",
       "      <td>(consummation, of, the, transactions, contempl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>london borough</td>\n",
       "      <td>(london, borough)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2025 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase  \\\n",
       "0                              including attorneys fees   \n",
       "1                     without the prior written consent   \n",
       "2                                      act u s c et seq   \n",
       "3                          subject to the provisions of   \n",
       "4                                 internal revenue code   \n",
       "...                                                 ...   \n",
       "2036  not reasonably be expected to result in a mate...   \n",
       "2037                  represents warrants and covenants   \n",
       "2038                                   taken or omitted   \n",
       "2039      consummation of the transactions contemplated   \n",
       "2040                                     london borough   \n",
       "\n",
       "                                              tokenized  word_count  \n",
       "0                          (including, attorneys, fees)           3  \n",
       "1               (without, the, prior, written, consent)           5  \n",
       "2                               (act, u, s, c, et, seq)           6  \n",
       "3                    (subject, to, the, provisions, of)           5  \n",
       "4                             (internal, revenue, code)           3  \n",
       "...                                                 ...         ...  \n",
       "2036  (not, reasonably, be, expected, to, result, in...          11  \n",
       "2037             (represents, warrants, and, covenants)           4  \n",
       "2038                               (taken, or, omitted)           3  \n",
       "2039  (consummation, of, the, transactions, contempl...           5  \n",
       "2040                                  (london, borough)           2  \n",
       "\n",
       "[2025 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('not only_stopwords', inplace=True)\n",
    "df.drop(columns='only_stopwords', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d1830-84df-45b3-9191-82134ef68a7d",
   "metadata": {},
   "source": [
    "Split into separate dataframes for different ngram lengths to avoid memory overflow with frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddca0ba8-461c-4e03-aa03-b6a9c5ea1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = df.word_count.unique().tolist() # List of all ngram lengths in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b938ec4-f581-49ec-94b7-a25a50fba267",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_phrases = {}\n",
    "for n in ns:\n",
    "    set_phrases[n] = df.query('word_count == @n').drop(columns='word_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f373a3e-2393-47bc-a3f7-1408369a8daa",
   "metadata": {},
   "source": [
    "Calculate relative frequency of each ngram (its count in the frequency distribution for the particular n divided by max count in this distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710d2465-7eda-4ecd-9111-82dfd52b7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_freq(tokenized_ngram, fdist):\n",
    "    '''Relative frequency of n-gram in the frequency distribution for this n'''\n",
    "    return fdist[tokenized_ngram] / fdist[fdist.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6be029d0-c298-4bd2-92f6-e0e44a24623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [05:55<00:00, 22.25s/it]\n"
     ]
    }
   ],
   "source": [
    "%%chime\n",
    "for n in tqdm(ns):\n",
    "    fdist = nltk.FreqDist(nltk.ngrams(tokens, n))\n",
    "    max_count = fdist[fdist.max()]\n",
    "    set_phrases[n]['rel_ngram_freq'] = set_phrases[n].tokenized.apply(lambda x: fdist[x] / max_count)\n",
    "    set_phrases[n]['count_per_million_tokens'] = set_phrases[n].tokenized.apply(lambda x: fdist[x] / n_tokens)\n",
    "    set_phrases[n].sort_values('rel_ngram_freq', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ec27a91-5239-4a3d-b33b-5d9024b02158",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('set_phrases.xlsx') as writer:  \n",
    "    for n in ns:\n",
    "        set_phrases[n].to_excel(writer, sheet_name=str(n))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
